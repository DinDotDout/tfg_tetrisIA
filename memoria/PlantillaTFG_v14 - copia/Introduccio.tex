%!TeX root=MemoriaTFG.tex

\chapter{Introduction}
\section{Artificial intelligence in video games}

AI has been present in video games since the very beginning.
Its purpose has always been to improve the players experience and the methods that have been used to implement such behaviours are vast, ranging from finite state machines and increasingly more complex enemy movement patterns tied to the game difficulty/level, to combining different advanced methods like pathfinding and decision trees. Other techniques related to machine learning such as reinforcement learning can currently also be found in some games. All these methods are mostly used for \ac{NPC}s and the information they perceive from the environment can be given in two different ways, via sensors, which provide a limited vision of the game world, or via the game’s own stored information e.g., the player’s exact location.

Due to an increasing interest in artificial intelligence in recent years, people have started to try and beat their favourite games with it. When taking this approach, we must first consider how the agent is going to perceive the game, having the same two options we talked about before. This time we usually encounter a major inconvenience, we do not have direct access to the game information due to us not being the game developers, although thanks to some \ac{API}(such as OpenAI Gym) we can access the game and thus base our agent’s information on it. Unfortunately, those APIs mostly feature older games, which limits us to the ones provided by it. Hence comes the need for image processing tools to extract data, though this may not necessarily be done by us, as will be shown later.

Due to the increasingly more difficult games being beaten, has also come a need for more intricate agents, leading to the drop of simpler techniques in favour of reinforcement learning (many times paired with those old techniques in order to provide the agent with basic behavioural guidance). This has ended up providing much better results than previously achieved in highly complex environments, and also helped discover new strategies in the own game. Even exploits in the system have sometimes been found, like in the case of an OpenAi project, where in a hide and seek game, the agents managed to abuse the physics engine in various ways. 

%\hypertarget{openai}{openai}

\section{Objectives and setbacks}

The overall goal of the project has already been discussed, but what will be called a success has not yet been defined.
Building an AI capable of playing Tetris has already been done many times before with great success, although the challenge trying to be taken on has a few more major and minor hindrances.

First of all, as a minor inconvenience, the Tetris version we are building our AI on features the \ac{SRS}, which is a modern rotation system with some unconventional situational rotations. No implementation that can be used has been found, neither as an OpenAI gym nor as simple game. Because of this, an entire game replicating Tetris 99 must be built from scratch to train our model.

Secondly, there is not a standardized way to access the console’s controller port from a PC, so a reliable workaround must be built and adapted. This is probably the biggest setback.

Lastly, and as a result of having to intercommunicate both devices, some extra delay, that we hope will not heavily interfere, will occur when bringing everything together.

Having mentioned the setbacks we first encounter, we expect to build an agent that plays tetris to near perfection, never loosing a game and trying to make as many points as possible in the least amount of time. If anything, we expect only the conditions outside the agents power to make it perform badly, namely bad screen detections or missed inputs. This means that once a good enough agent has been built, our main focus will shift onto making it perform as closely as possible to its intended actions on the console. 

\section{Task division}

In order to reach our goal, we have to tackle the problems one by one. Thus, the means by which the results in the project have been obtained consist of dividing it into four different modules:
\begin{itemize}
	\item	Switch-PC interface: The way in which the pc is able to communicate with the console.

\item	Information capture: How the console’s information is sent to the pc and then processed for use by the neural net.

\item	Machine learning: How the AI is able to learn. Includes the training environment explanation, the heuristic used and how it was chosen.

\item	Decision making: Defines how the information extracted by the information capture module is treated right before it is finally ready to be sent to the net. It also explains how the output is adapted and transferred to the console correctly.
\end{itemize}

The aforementioned modules will be further explained later, in their corresponding section in the document but, it needs to be mentiones that the whole project has been made in python given its many machine learning library options.








